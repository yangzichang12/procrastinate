{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "import torch\n",
    "import math\n",
    "import IPython\n",
    "from pyvis.network import Network\n",
    "import wikipedia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the relation extraction model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Laoding model and Tokenizers\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Babelscape/rebel-large\")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"Babelscape/rebel-large\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Offering 2 types of text to Knowledge Base\n",
    "1. Short text to Knowledge Base (Feeding summarised text to build KB)\n",
    "2. Long Text to Knowledge Base (Feeding non-summarised text to build KB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_relations_from_model_output(text):\n",
    "    relations = []\n",
    "    relation, subject, relation, object_ = '', '', '', ''\n",
    "    text = text.strip()\n",
    "    current = 'x'\n",
    "    text_replaced = text.replace(\"<s>\", \"\").replace(\"<pad>\", \"\").replace(\"</s>\", \"\")\n",
    "    for token in text_replaced.split():\n",
    "        if token == \"<triplet>\":\n",
    "            current = 't'\n",
    "            if relation != '':\n",
    "                relations.append({\n",
    "                    \"head\": subject.strip(),\n",
    "                    \"type\": relation.strip(),\n",
    "                    \"tail\": object_.strip()\n",
    "                })\n",
    "                relation = ''\n",
    "            subject = ''\n",
    "        elif token == \"<subj>\":\n",
    "            current = 's'\n",
    "            if relation != '':\n",
    "                relations.append({\n",
    "                    \"head\": subject.strip(),\n",
    "                    \"type\": relation.strip(),\n",
    "                    \"tail\": object_.strip()\n",
    "                })\n",
    "            object_ = ''\n",
    "        elif token == \"<obj>\":\n",
    "            current = 'o'\n",
    "            relation = ''\n",
    "        else:\n",
    "            if current == 't':\n",
    "                subject += ' ' + token\n",
    "            elif current == 's':\n",
    "                object_ += ' ' + token\n",
    "            elif current == 'o':\n",
    "                relation += ' ' + token\n",
    "    \n",
    "    if subject != '' and relation != '' and object_ != '':\n",
    "        relations.append({\n",
    "            \"head\": subject.strip(),\n",
    "            \"type\": relation.strip(),\n",
    "            \"tail\": object_.strip()\n",
    "        })\n",
    "    \n",
    "    return relations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementing a KB class to deal with adding new relations to the Knowledge base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KB():\n",
    "    def __init__(self):\n",
    "        self.relations = []\n",
    "\n",
    "    def are_relations_equal(self, r1, r2):\n",
    "        return all(r1[attr] == r2[attr] for attr in [\"head\", \"type\", \"tail\"])\n",
    "    \n",
    "    def exists_relation(self, r1):\n",
    "        return any(self.are_relations_equal(r1, r2) for r2 in self.relations)\n",
    "    \n",
    "    def merge_relations(self, r1):\n",
    "        r2 = [r for r in self.relations if self.are_relations_equal(r1, r)[0]]\n",
    "        spans_to_add = [span for span in r1[\"meta\"][\"spans\"] if span not in r2[\"meta\"][\"spans\"]]\n",
    "        r2[\"meta\"][\"spans\"] += spans_to_add\n",
    "    \n",
    "    def add_relations(self, r):\n",
    "        if not self.exists_relation(r):\n",
    "            self.relations.append(r)\n",
    "        else:\n",
    "            self.merge_relations(r)\n",
    "\n",
    "    def print(self):\n",
    "        print(\"Relations:\")\n",
    "        for r in self.relations:\n",
    "            print(f\"  {r}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining a function that returns KB object with relations extracted from a short text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def from_small_text_to_kb(text, verbose=False):\n",
    "    kb = KB()\n",
    "\n",
    "    # Tokenizer text\n",
    "    model_inputs = tokenizer(text, max_length=512, padding=True, truncation=True, return_tensors='pt')\n",
    "    if verbose:\n",
    "        print(f\"Num tokens: {len(model_inputs)}\")\n",
    "\n",
    "    # Generate\n",
    "    gen_kwargs = {\n",
    "        \"max_length\": 216,\n",
    "        \"length_penalty\": 0,\n",
    "        \"num_beams\": 3,\n",
    "        \"num_return_sequences\": 3\n",
    "    }\n",
    "    generated_tokens = model.generate(\n",
    "        **model_inputs,\n",
    "        **gen_kwargs,\n",
    "    )\n",
    "    decoded_preds = tokenizer.batch_decode(generated_tokens, skip_special_tokens=False)\n",
    "\n",
    "    # Creating the KB\n",
    "    for sentence_pred in decoded_preds:\n",
    "        relations = extract_relations_from_model_output(sentence_pred)\n",
    "        for r in relations:\n",
    "            kb.add_relations(r)\n",
    "    \n",
    "    return kb\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading text from the CMU intro lecture transcript and build a knowledge graph on it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Welcome to Computer Graphics 15462-662 at Carnegie Mellon University. I'm Kenan Crane. I'm a professor of computer science and robotics. And I also do research in computer graphics, so specifically in the area of geometric algorithms. The purpose of this video is to give you all the information that you'll need to succeed this semester. So periodically we'll upload little videos to cover administrative things, to talk about what's been going on this week, and to answer any significant questions that have come up. I should also say that all the information today is available on the course webpage at 15462.courses.cs.cmu.edu. So please go ahead, check out that link, read through especially the course info page in detail because there's a lot of things that I won't say here in this video but that are important for you to know as you go through the course. we have a great set of TAs this semester. So if you have any questions, please at any time, feel free to email them, email me, post a question on Piazza, whatever you like to do, but don't be shy about getting in touch. The first things you should do to get running with the course is to sign up for Piazza. So go to piazza.com slash CMU, find our course 462 and sign up. And second, to sign up for an account on the course webpage. Click on the login button in the upper right and you should see a link that says sign up to sign up you will need a special passcode which is available only on Piazza so you'd better sign up for Piazza first before you sign up for the course webpage I should also say if you're not officially enrolled in this course yet, don't worry. First of all, usually there's no trouble getting in. We don't really have much of a class size limitation this semester. Just sign up for the webpage, get rolling, start reading through the assignments and so forth, so that if you do decide to add the course you're on track. So we will be running the whole course remotely and it basically has three components. We have lectures, we have recitations, and we have office hours which will all be done online. The recitations and the office hours will be done through Zoom, and you'll be able to find the appropriate Zoom links on Piazza. The lectures will be pre-recorded videos that you can watch on YouTube, but we will be there during the lecture period to answer questions that might come up while you watch these videos. So if you're watching the video, something doesn't make sense, just hit pause, go to the Zoom room, talk to us, ask us questions, and then go back to your video. A couple of tips, it can be really hard, I know, when you're sitting at home to pay attention to a long 80-minute lecture video. So a couple of things that our students have found are useful. One is to simply speed up the video, which you can do using YouTube. So if you've never done that before, you can give that a try right now. Go to the bottom right, you should see a little gear icon and you'll see a little option for playback speed so you can speed up the video as fast as you can as fast as you can take it the other thing that can be very helpful is to just break up watching the video into chunks so if it's 80 minutes long, maybe you break it up into 40 minutes today and 40 minutes tomorrow. That can really help to keep focused. In terms of work that you'll have to do for this course, they're really just three main things. There are many homeworks. So this is just two or three questions that we're going to ask after each lecture to just make sure that you understand what's going on then there's four major coding assignments so over the course of the semester you're going to build up a 3d package called scotty 3d and scotty 3d is just like any modern 3d package it has modeling it has rendering it has animation but the difference is all of the key routines have been stripped out and you're gonna go ahead and fill them in and hopefully be able to create some really cool content, really cool models and animations. And finally, we will have a midterm and a final, but please do not sweat about this. Each of these is worth only 10% of your grade. This is mainly just a checkpoint to make sure that you understand conceptually what's going on in the course, not just the coding. Also, please be aware that you have five late days, which you can use completely at your discretion. You don't have to ask us, can I use it for this or that? Just go ahead and use it. In terms of collaboration, we encourage people to talk to their peers, to have interesting conversations on Piazza, to come to office hours and ask whatever you like, but your final work must be your own. All assignments in this class will be individual work. All the details, again, you can find on the webpage about collaboration and cheating and so forth. Okay, that's it. So if you have questions, please don't hesitate to reach out and contact us on Piazza, on email, whatever you like. Otherwise, if you're excited about getting rolling, you can start watching the first lecture right away. So just go to the course webpage, you'll see our course schedule, and you can just click on the video links to get started. So that's it. Looking forward to seeing you this semester.\n"
     ]
    }
   ],
   "source": [
    "cmu_lecture_transcript_path = \"cmu_computer_graphics_intro_voice_transcribed.txt\"\n",
    "with open(cmu_lecture_transcript_path) as src:\n",
    "    cmu_lecture_text = src.read()\n",
    "\n",
    "print(cmu_lecture_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The KB build is below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num tokens: 2\n",
      "Relations:\n",
      "  {'head': 'Kenan Crane', 'type': 'field of work', 'tail': 'computer graphics'}\n",
      "  {'head': 'computer graphics', 'type': 'part of', 'tail': 'computer science'}\n",
      "  {'head': 'Computer Graphics 15462-662', 'type': 'main subject', 'tail': 'computer science'}\n"
     ]
    }
   ],
   "source": [
    "kb = from_small_text_to_kb(cmu_lecture_text, verbose=True)\n",
    "kb.print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a text_to_kb function that manages the texts with spanning logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def from_text_to_kb(text, span_length=128, verbose=False):\n",
    "    # tokenize whole text\n",
    "    inputs = tokenizer([text], return_tensors=\"pt\")\n",
    "\n",
    "    # compute span boundaries\n",
    "    num_tokens = len(inputs[\"input_ids\"][0])\n",
    "    if verbose:\n",
    "        print(f\"Input has {num_tokens} tokens\")\n",
    "    num_spans = math.ceil(num_tokens / span_length)\n",
    "    if verbose:\n",
    "        print(f\"Input has {num_spans} spans\")\n",
    "    overlap = math.ceil((num_spans * span_length - num_tokens) / \n",
    "                        max(num_spans - 1, 1))\n",
    "    spans_boundaries = []\n",
    "    start = 0\n",
    "    for i in range(num_spans):\n",
    "        spans_boundaries.append([start + span_length * i,\n",
    "                                 start + span_length * (i + 1)])\n",
    "        start -= overlap\n",
    "    if verbose:\n",
    "        print(f\"Span boundaries are {spans_boundaries}\")\n",
    "\n",
    "    # transform input with spans\n",
    "    tensor_ids = [inputs[\"input_ids\"][0][boundary[0]:boundary[1]]\n",
    "                  for boundary in spans_boundaries]\n",
    "    tensor_masks = [inputs[\"attention_mask\"][0][boundary[0]:boundary[1]]\n",
    "                    for boundary in spans_boundaries]\n",
    "    inputs = {\n",
    "        \"input_ids\": torch.stack(tensor_ids),\n",
    "        \"attention_mask\": torch.stack(tensor_masks)\n",
    "    }\n",
    "\n",
    "    # generate relations\n",
    "    num_return_sequences = 3\n",
    "    gen_kwargs = {\n",
    "        \"max_length\": 256,\n",
    "        \"length_penalty\": 0,\n",
    "        \"num_beams\": 3,\n",
    "        \"num_return_sequences\": num_return_sequences\n",
    "    }\n",
    "    generated_tokens = model.generate(\n",
    "        **inputs,\n",
    "        **gen_kwargs,\n",
    "    )\n",
    "\n",
    "    # decode relations\n",
    "    decoded_preds = tokenizer.batch_decode(generated_tokens,\n",
    "                                           skip_special_tokens=False)\n",
    "\n",
    "    # create kb\n",
    "    kb = KB()\n",
    "    i = 0\n",
    "    for sentence_pred in decoded_preds:\n",
    "        current_span_index = i // num_return_sequences\n",
    "        relations = extract_relations_from_model_output(sentence_pred)\n",
    "        for relation in relations:\n",
    "            relation[\"meta\"] = {\n",
    "                \"spans\": [spans_boundaries[current_span_index]]\n",
    "            }\n",
    "            kb.add_relation(relation)\n",
    "        i += 1\n",
    "\n",
    "    return kb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performing entity linking\n",
    "This is to make sure that entities that are similar to each other are merged into a single entity and prevents overly large clusters (We are using Wikipedia for this purpose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the modified version of the KB class\n",
    "class KB():\n",
    "    def __init__(self):\n",
    "        self.entities = {}\n",
    "        self.relations = []\n",
    "\n",
    "    def are_relations_equal(self, r1, r2):\n",
    "        return all(r1[attr] == r2[attr] for attr in [\"head\", \"type\", \"tail\"])\n",
    "    \n",
    "    def get_wikipedia_data(self, candidate_entity):\n",
    "        try:\n",
    "            page = wikipedia.page(candidate_entity, auto_suggest=False)\n",
    "            entity_data = {\"title\": page.title,\n",
    "                           \"url\": page.url,\n",
    "                           \"summary\": page.summary}\n",
    "            return entity_data\n",
    "        except:\n",
    "            return None\n",
    "        \n",
    "    def add_entity(self, e):\n",
    "        self.entities[e[\"title\"]] = {k:v for k, v in e.items() if k != \"title\"}\n",
    "\n",
    "    def exists_relation(self, r1):\n",
    "        return any(self.are_relations_equal(r1, r2) for r2 in self.relations)\n",
    "    \n",
    "    def merge_relations(self, r1):\n",
    "        r2 = [r for r in self.relations if self.are_relations_equal(r1, r)[0]]\n",
    "        spans_to_add = [span for span in r1[\"meta\"][\"spans\"] if span not in r2[\"meta\"][\"spans\"]]\n",
    "        r2[\"meta\"][\"spans\"] += spans_to_add\n",
    "    \n",
    "    def add_relations(self, r):\n",
    "        # We now first check on wikipedia\n",
    "        candidate_entities = [r[\"head\"], r[\"tail\"]]\n",
    "        entities = [self.get_wikipedia_data(ent) for ent in candidate_entities]\n",
    "\n",
    "        # If one of the entities does not exist, stop\n",
    "        if any(ent is None for ent in entities):\n",
    "            return\n",
    "        \n",
    "        # Managing new entities\n",
    "        for e in entities:\n",
    "            self.add_entity(e)\n",
    "\n",
    "        # Renaming relation entities with their wikipedia titles\n",
    "        r[\"head\"] = entities[0][\"title\"]\n",
    "        r[\"tail\"] = entities[1][\"title\"]\n",
    "\n",
    "        # Managing the new relation\n",
    "        if not self.exists_relation(r):\n",
    "            self.relations.append(r)\n",
    "        else:\n",
    "            self.merge_relations(r)\n",
    "\n",
    "    def print(self):\n",
    "        print(\"Entities:\")\n",
    "        for e in self.entities.items():\n",
    "            print(f\"  {e}\")\n",
    "        print(\"Relations:\")\n",
    "        for r in self.relations:\n",
    "            print(f\"  {r}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Pyvis to visualise the knowledge base that is built\n",
    "Defining a save_network_html function that:\n",
    "1. Initializes an empty directed pyvis network\n",
    "2. Add the knowledge base entities as nodes\n",
    "3. Adds the knowledge base relations as edges\n",
    "4. Save the network in HTML file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_network_html(kb, filename=\"network.html\"):\n",
    "    # Creating the empty network\n",
    "    net = Network(directed=True, width=\"700px\", height=\"700px\", bgcolor=\"#eeeeee\")\n",
    "\n",
    "    # nodes\n",
    "    color_entity = \"#00FF00\"\n",
    "    for e in kb.entities:\n",
    "        net.add_node(e, shape=\"circle\", color=color_entity)\n",
    "\n",
    "    # Edges\n",
    "    for r in kb.relations:\n",
    "        net.add_edge(r[\"head\"], r[\"tail\"], title=r[\"type\"], label=r[\"type\"])\n",
    "\n",
    "    # Saving the network\n",
    "    net.repulsion(node_distance=200,\n",
    "                  central_gravity=0.2,\n",
    "                  spring_length=200,\n",
    "                  spring_strength=0.05,\n",
    "                  damping=0.09)\n",
    "    net.set_edge_smooth(\"dynamic\")\n",
    "    net.show(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "procrastinate",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
